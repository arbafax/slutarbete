# **VIKTIGT** Denna dokumentation är automatgenererad och _**inte**_ verifierad 2025-12-01

# RAG Search System - Konfigurationsfil (.env)
# 
# INSTRUKTIONER:
# 1. Byt namn på denna fil från "env.template" till ".env"
# 2. Fyll i dina API-nycklar nedan
# 3. Spara filen
# 4. Starta om servern
#
# VIKTIGT: Dela ALDRIG denna fil med andra när du fyllt i dina nycklar!
#

# ==============================================================================
# OBLIGATORISKA INSTÄLLNINGAR
# ==============================================================================

# Google Gemini API Key (KRÄVS för grundfunktionalitet)
# Skaffa gratis på: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=

# ==============================================================================
# VALFRIA API-NYCKLAR
# ==============================================================================

# OpenAI API Key (valfri - för OpenAI embeddings och GPT-modeller)
# Skaffa på: https://platform.openai.com/api-keys
# OPENAI_API_KEY=

# Cohere API Key (valfri - för Cohere embeddings)
# Skaffa på: https://dashboard.cohere.com/api-keys
# COHERE_API_KEY=

# ==============================================================================
# SYSTEM-INSTÄLLNINGAR
# ==============================================================================

# Debug-läge (sätt till true för detaljerad loggning)
DEBUG=false

# Maximal filstorlek för uppladdning (i bytes)
# Standard: 100000000 (100 MB)
# MAX_UPLOAD_SIZE=100000000

# ==============================================================================
# STANDARDVÄRDEN (valfria, avkommentera för att ändra)
# ==============================================================================

# Standard chunk-storlek för text-segmentering
# Mindre värde = snabbare men mindre kontext
# Större värde = mer kontext men långsammare
# DEFAULT_CHUNK_SIZE=512

# Standard embedding backend
# Alternativ: google, openai, cohere, bge, e5, sbert, ollama
# DEFAULT_EMBEDDING_BACKEND=google

# Standard LLM backend för AI-frågor
# Alternativ: google, openai, ollama
# DEFAULT_LLM_BACKEND=google

# ==============================================================================
# OLLAMA-INSTÄLLNINGAR (endast om du använder lokal Ollama)
# ==============================================================================

# Ollama server URL
# OLLAMA_HOST=http://localhost:11434

# Ollama embedding-modell
# OLLAMA_EMBED_MODEL=nomic-embed-text

# Ollama LLM-modell
# OLLAMA_LLM_MODEL=llama3.2

# ==============================================================================
# AVANCERADE INSTÄLLNINGAR
# ==============================================================================

# Antal worker-processer för Uvicorn (auto = antal CPU-kärnor)
# WORKERS=auto

# Log-nivå (DEBUG, INFO, WARNING, ERROR, CRITICAL)
# LOG_LEVEL=INFO

# Timeout för web scraping (i sekunder)
# SCRAPING_TIMEOUT=30

# Maximal sökdjup för hierarkisk markdown-parsing
# MAX_HEADING_LEVEL=6

# ==============================================================================
# SÄKERHETSINSTÄLLNINGAR
# ==============================================================================

# Tillåtna CORS origins (kommaseparerad lista)
# Standard: * (alla origins tillåtna)
# För produktion, specificera exakta domäner:
# CORS_ORIGINS=https://example.com,https://app.example.com
# CORS_ORIGINS=*

# API rate limiting (requests per minut)
# API_RATE_LIMIT=100

# ==============================================================================
# EXEMPEL PÅ IFYLLD KONFIGURATION
# ==============================================================================
# 
# GOOGLE_API_KEY=AIzaSyD1234567890abcdefghijklmnopqrstu
# OPENAI_API_KEY=sk-proj-abc123def456ghi789jkl012mno345pqr678stu
# COHERE_API_KEY=abc123def456ghi789jkl012mno345pqr678stu901vwx
# DEBUG=false
#
